{
  "components": {
    "comp-add-external-data": {
      "executorLabel": "exec-add-external-data",
      "inputDefinitions": {
        "artifacts": {
          "test_file": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          },
          "train_file": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "external_info_file": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "test_enriched_file": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          },
          "train_enriched_file": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-calculate-and-aggregate-features": {
      "executorLabel": "exec-calculate-and-aggregate-features",
      "inputDefinitions": {
        "artifacts": {
          "train_df_path": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          },
          "trajectory_df_path": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "flight_phases_refinement": {
            "parameterType": "BOOLEAN"
          },
          "use_trajectory": {
            "parameterType": "BOOLEAN"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "aggregated_features_path": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-calculate-flight-duration": {
      "executorLabel": "exec-calculate-flight-duration",
      "inputDefinitions": {
        "artifacts": {
          "input_df": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_df": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-clean-dataframe-with-isolation-forest": {
      "executorLabel": "exec-clean-dataframe-with-isolation-forest",
      "inputDefinitions": {
        "artifacts": {
          "input_df": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "contamination": {
            "defaultValue": 0.01,
            "isOptional": true,
            "parameterType": "NUMBER_DOUBLE"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_df": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-clean-trajectory-with-isolation-forest": {
      "executorLabel": "exec-clean-trajectory-with-isolation-forest",
      "inputDefinitions": {
        "artifacts": {
          "input_df": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "contamination": {
            "defaultValue": 0.01,
            "isOptional": true,
            "parameterType": "NUMBER_DOUBLE"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_df": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-encode-categorical-features": {
      "executorLabel": "exec-encode-categorical-features",
      "inputDefinitions": {
        "artifacts": {
          "input_file": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "preserve_columns": {
            "parameterType": "LIST"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_file": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-load-data": {
      "executorLabel": "exec-load-data",
      "inputDefinitions": {
        "parameters": {
          "data_path": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "test_file": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          },
          "train_file": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          },
          "trajectory_file": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-normalize-dataframe": {
      "executorLabel": "exec-normalize-dataframe",
      "inputDefinitions": {
        "artifacts": {
          "input_file": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "exclude_columns": {
            "parameterType": "LIST"
          },
          "split_by_flown_distance": {
            "defaultValue": false,
            "isOptional": true,
            "parameterType": "BOOLEAN"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_file": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    }
  },
  "deploymentSpec": {
    "executors": {
      "exec-add-external-data": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "add_external_data"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'fsspec' 'gcsfs' 'kfp==2.0.0' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef add_external_data(\n        train_file: InputPath(\"CSV\"),\n        test_file: InputPath(\"CSV\"),\n        external_info_file: str,\n        train_enriched_file: OutputPath(\"CSV\"),\n        test_enriched_file: OutputPath(\"CSV\"),\n):\n    \"\"\"Adds external aircraft information.\"\"\"\n    import pandas as pd\n    import fsspec\n    import json\n\n    # Read JSON file from GCS using fsspec\n    with fsspec.open(external_info_file, \"r\") as file:\n        external_information = json.load(file)\n\n    external_df = pd.DataFrame.from_dict(external_information, orient=\"index\")\n    external_df.reset_index(inplace=True)\n    external_df.rename(columns={\"index\": \"aircraft_type\"}, inplace=True)\n\n    train_df = pd.read_csv(train_file)\n    test_df = pd.read_csv(test_file)\n\n    train_enriched = pd.merge(train_df, external_df, on=\"aircraft_type\",\n                              how=\"left\")\n    test_enriched = pd.merge(test_df, external_df, on=\"aircraft_type\",\n                             how=\"left\")\n\n    train_enriched.to_csv(train_enriched_file, index=False)\n    test_enriched.to_csv(test_enriched_file, index=False)\n\n"
          ],
          "image": "python:3.7"
        }
      },
      "exec-calculate-and-aggregate-features": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "calculate_and_aggregate_features"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'numpy' 'tqdm' 'scipy' 'kfp==2.0.0' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef calculate_and_aggregate_features(\n    trajectory_df_path: InputPath(\"CSV\"),\n    train_df_path: InputPath(\"CSV\"),\n    aggregated_features_path: OutputPath(\"CSV\"),\n    use_trajectory: bool,\n    flight_phases_refinement: bool,\n):\n    \"\"\"Calculates thrust minus drag for flight phases and aggregates features.\"\"\"\n    import pandas as pd\n    import numpy as np\n    from scipy import signal\n    from tqdm import tqdm\n\n    import math\n\n    trajectory_df = pd.read_csv(trajectory_df_path)\n    train_df = pd.read_csv(train_df_path)\n    ktstofts = 1.6878098571012\n\n    def isa(alt):\n        T0 = 288.15\n        p0 = 101325\n        rho0 = 1.225\n        a0 = 340.294\n        k = 1.4\n        R = 287.05287\n        betabelow = -0.0065\n        trop = 11000\n\n        if alt < 0 or alt > 47000:\n            print(\"Altitude must be in [0, 47000]\")\n            return None, None\n\n        if alt == 0:\n            return T0, rho0\n\n        if 0 < alt <= trop:\n            temperature = T0 + betabelow * alt\n            pressure = p0 * (temperature / T0) ** ((-1) * 9.80665 / (betabelow * R))\n        elif trop < alt < 47000:\n            temperature = T0 + betabelow * trop\n            pressure = (\n                p0 * (temperature / T0) ** ((-1) * 9.80665 / (betabelow * R))\n            ) * math.exp(-9.80665 * (alt - trop) / (R * temperature))\n\n        density = pressure / (R * temperature)\n        return temperature, density\n\n    def calculate_true_airspeed(row):\n        GS = row[\"groundspeed\"]\n        track = np.radians(row[\"track\"])\n        u_wind = row[\"u_component_of_wind\"]\n        v_wind = row[\"v_component_of_wind\"]\n\n        V = (\n            np.sqrt(\n                (GS * np.sin(track) - u_wind) ** 2 + (GS * np.cos(track) - v_wind) ** 2\n            )\n            * ktstofts\n        )\n        return V\n\n    def calculate_vertical_speed(row):\n        return row[\"vertical_rate\"] / 60\n\n    def calculate_temp_deviation(row):\n        isa_temp, _ = isa(row[\"altitude\"])\n        return row[\"temperature\"] - isa_temp\n\n    def calculate_horizontal_acceleration(group):\n        group = group.sort_values(\"timestamp\")\n        group[\"V\"] = group.apply(calculate_true_airspeed, axis=1)\n        group[\"dV_dt\"] = (\n            group[\"V\"].diff() / group[\"timestamp\"].diff().dt.total_seconds()\n        )\n        return group\n\n    def calculate_wind_acceleration(group):\n        group = group.sort_values(\"timestamp\")\n        group[\"W_long\"] = (\n            group[\"u_component_of_wind\"] * np.sin(np.radians(group[\"track\"]))\n            + group[\"v_component_of_wind\"] * np.cos(np.radians(group[\"track\"]))\n        ) * ktstofts\n        group[\"dWi_dt\"] = (\n            group[\"W_long\"].diff() / group[\"timestamp\"].diff().dt.total_seconds()\n        )\n        return group\n\n    def identify_flight_phases(group, flight_phases_refinement=False):\n        group = group.sort_values(\"timestamp\").reset_index(drop=True)\n        group[\"altitude_diff\"] = group[\"altitude\"].diff()\n\n        # Applies a Savitzky-Golay filter to smooth the altitude profile, reducing noise.\n        altitude_smooth = signal.savgol_filter(\n            group[\"altitude\"],\n            window_length=min(21, len(group) // 2 * 2 + 1),\n            polyorder=3,\n        )\n\n        # Calculate the rate of climb (ROC)\n        group[\"ROC\"] = np.gradient(\n            altitude_smooth, group[\"timestamp\"].astype(int) / 10**9\n        )\n        max_altitude = group[\"altitude\"].max()\n        takeoff_end = group[group[\"altitude\"] > group[\"altitude\"].quantile(0.1)].index[\n            0\n        ]\n        top_of_climb = group[group[\"altitude\"] > max_altitude * 0.95].index[0]\n\n        takeoff_phase = group.loc[:takeoff_end]\n        initial_climb_phase = group.loc[takeoff_end:top_of_climb]\n        cruise_phase = group.loc[top_of_climb:]\n\n        if flight_phases_refinement:\n            # Refine takeoff phase (focus on the most significant part of the takeoff)\n            takeoff_phase = takeoff_phase[\n                takeoff_phase[\"ROC\"] > takeoff_phase[\"ROC\"].quantile(0.5)\n            ]\n\n            # Refine initial climb phase\n            initial_climb_phase = initial_climb_phase[\n                (initial_climb_phase[\"ROC\"] > initial_climb_phase[\"ROC\"].quantile(0.25))\n                & (initial_climb_phase[\"altitude\"] < max_altitude * 0.8)\n            ]\n\n        return takeoff_phase, initial_climb_phase, cruise_phase\n\n    def calculate_thrust_minus_drag_for_phases(trajectory_df, flight_phases_refinement):\n        td_list = []\n\n        for flight_id, group in tqdm.tqdm(\n            trajectory_df.groupby(\"flight_id\"), desc=\"Calculating T-D for each flight\"\n        ):\n            takeoff_phase, initial_climb_phase, _ = identify_flight_phases(\n                group, flight_phases_refinement\n            )\n\n            # You can combine takeoff and initial climb if desired\n            relevant_phase = pd.concat([takeoff_phase, initial_climb_phase])\n\n            if relevant_phase.empty:\n                continue\n\n            # Perform calculations only on the relevant phase\n            relevant_phase[\"V\"] = relevant_phase.apply(calculate_true_airspeed, axis=1)\n            relevant_phase[\"dh_dt\"] = relevant_phase.apply(\n                calculate_vertical_speed, axis=1\n            )\n            relevant_phase[\"delta_t\"] = relevant_phase.apply(\n                calculate_temp_deviation, axis=1\n            )\n\n            relevant_phase = calculate_horizontal_acceleration(relevant_phase)\n            relevant_phase = calculate_wind_acceleration(relevant_phase)\n\n            # Calculate T - D\n            relevant_phase[\"T_minus_D\"] = (\n                32.17405\n                * relevant_phase[\"dh_dt\"]\n                / relevant_phase[\"V\"]\n                * (\n                    relevant_phase[\"temperature\"]\n                    / (relevant_phase[\"temperature\"] - relevant_phase[\"delta_t\"])\n                )\n                + relevant_phase[\"dV_dt\"]\n                + relevant_phase[\"dWi_dt\"]\n            )\n\n            # Add flight ID for linking later\n            relevant_phase[\"flight_id\"] = flight_id\n\n            # Collect the relevant data\n            td_list.append(relevant_phase)\n\n        # Concatenate all flights' data\n        td_df = pd.concat(td_list, ignore_index=True)\n\n        # Drop any rows with missing T_minus_D values\n        td_df = td_df.dropna(subset=[\"T_minus_D\"])\n\n        return td_df\n\n    def aggregate_features(td_df):\n        numerical_cols = td_df.select_dtypes(include=np.number).columns.tolist()\n        if \"flight_id\" in numerical_cols:\n            numerical_cols.remove(\"flight_id\")\n        agg_funcs = {col: [\"mean\", \"ax\", \"td\"] for col in numerical_cols}\n        aggregated_features = td_df.groupby(\"flight_id\").agg(agg_funcs).reset_index()\n        aggregated_features.columns = [\n            \"_\".join(col).rstrip(\"_\") for col in aggregated_features.columns.values\n        ]\n\n        return aggregated_features\n\n    if use_trajectory:\n        td_df = calculate_thrust_minus_drag_for_phases(\n            trajectory_df, flight_phases_refinement\n        )\n        aggregated_features = aggregate_features(td_df)\n        merged_df = pd.merge(\n            train_df,\n            aggregated_features,\n            left_on=\"flight_id\",\n            right_on=\"flight_id\",\n            how=\"inner\",\n        )\n    else:\n        merged_df = train_df.copy()\n\n    merged_df.to_csv(aggregated_features_path, index=False)\n\n"
          ],
          "image": "python:3.7"
        }
      },
      "exec-calculate-flight-duration": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "calculate_flight_duration"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'kfp==2.0.0' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef calculate_flight_duration(input_df: InputPath(\"CSV\"), output_df: OutputPath(\"CSV\")):\n    \"\"\"Calculates flight duration in minutes.\"\"\"\n    import pandas as pd\n\n    def get_duration(df):\n        df[\"actual_offblock_time\"] = pd.to_datetime(df[\"actual_offblock_time\"])\n        df[\"arrival_time\"] = pd.to_datetime(df[\"arrival_time\"])\n        df[\"duration\"] = (\n            df[\"arrival_time\"] - df[\"actual_offblock_time\"]\n        ).dt.total_seconds() / 60\n        return df\n\n    df = pd.read_csv(input_df)\n    df_with_duration = get_duration(df)\n    df_with_duration.to_csv(output_df, index=False)\n\n"
          ],
          "image": "python:3.7"
        }
      },
      "exec-clean-dataframe-with-isolation-forest": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "clean_dataframe_with_isolation_forest"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'scikit-learn' 'pandas' 'numpy' 'kfp==2.0.0' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef clean_dataframe_with_isolation_forest(\n    input_df: InputPath(\"CSV\"),\n    output_df: OutputPath(\"CSV\"),\n    contamination: float = 0.01,\n):\n    \"\"\"Cleans a dataframe using Isolation Forest for outlier detection.\"\"\"\n    import pandas as pd\n    import numpy as np\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.ensemble import IsolationForest\n\n    df = pd.read_csv(input_df)\n    print(\"Shape before clean: \", df.shape)\n\n    cleaned_df = df.copy()\n    cleaned_df = cleaned_df.dropna()\n\n    numeric_columns = cleaned_df.select_dtypes(include=[np.number]).columns\n\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(cleaned_df[numeric_columns])\n\n    iso_forest = IsolationForest(contamination=contamination, random_state=42)\n    outlier_labels = iso_forest.fit_predict(scaled_data)\n\n    cleaned_df = cleaned_df[outlier_labels == 1].reset_index(drop=True)\n\n    print(\"Shape after clean: \", cleaned_df.shape)\n    cleaned_df.to_csv(output_df, index=False)\n\n"
          ],
          "image": "python:3.7"
        }
      },
      "exec-clean-trajectory-with-isolation-forest": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "clean_trajectory_with_isolation_forest"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'scikit-learn' 'pandas' 'numpy' 'kfp==2.0.0' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef clean_trajectory_with_isolation_forest(\n    input_df: InputPath(\"CSV\"),\n    output_df: OutputPath(\"CSV\"),\n    contamination: float = 0.01,\n):\n    \"\"\"Cleans a trajectory dataframe using Isolation Forest for outlier detection.\"\"\"\n    import pandas as pd\n    import numpy as np\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.ensemble import IsolationForest\n\n    df = pd.read_csv(input_df)\n    print(\"Shape before clean: \", df.shape)\n\n    cleaned_df = df.copy()\n\n    cleaned_df = cleaned_df[\n        (cleaned_df[\"altitude\"] >= 0) & (cleaned_df[\"altitude\"] <= 47000)\n    ]\n    cleaned_df = cleaned_df.dropna()\n\n    numeric_columns = cleaned_df.select_dtypes(include=[np.number]).columns\n\n    def clean_group(group):\n        if len(group) <= 1:\n            return group\n\n        scaler = StandardScaler()\n        scaled_data = scaler.fit_transform(group[numeric_columns])\n\n        iso_forest = IsolationForest(contamination=contamination, random_state=42)\n        outlier_labels = iso_forest.fit_predict(scaled_data)\n\n        return group[outlier_labels == 1]\n\n    cleaned_df = cleaned_df.groupby(\"flight_id\").apply(clean_group)\n\n    cleaned_df = cleaned_df.reset_index(drop=True)\n\n    print(\"Shape after clean: \", cleaned_df.shape)\n    cleaned_df.to_csv(output_df, index=False)\n\n"
          ],
          "image": "python:3.7"
        }
      },
      "exec-encode-categorical-features": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "encode_categorical_features"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'scikit-learn' 'kfp==2.0.0' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef encode_categorical_features(\n    input_file: InputPath(\"CSV\"), output_file: OutputPath(\"CSV\"), preserve_columns: list\n):\n    \"\"\"Encodes categorical features in the dataframe, with the option to preserve certain columns.\"\"\"\n    import pandas as pd\n    from sklearn.preprocessing import LabelEncoder\n\n    df = pd.read_csv(input_file)\n\n    df_encoded = df.copy()\n\n    categorical_col = [\n        \"adep\",\n        \"country_code_adep\",\n        \"ades\",\n        \"country_code_ades\",\n        \"aircraft_type\",\n        \"airline\",\n    ]\n\n    encoder = LabelEncoder()\n\n    for col in categorical_col:\n        df_encoded[col + \"_encoded\"] = encoder.fit_transform(df_encoded[col])\n        if col not in preserve_columns:\n            df_encoded = df_encoded.drop(columns=[col])\n\n    oneHot_col = [\"wtc\"]\n    df_encoded = pd.get_dummies(df_encoded, columns=oneHot_col)\n\n    df_encoded[\"wtc_M\"] = df_encoded[\"wtc_M\"].astype(int)\n    df_encoded[\"wtc_H\"] = df_encoded[\"wtc_H\"].astype(int)\n\n    df_encoded.to_csv(output_file, index=False)\n\n"
          ],
          "image": "python:3.7"
        }
      },
      "exec-load-data": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "load_data"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'fsspec' 'gcsfs' 'pyarrow' 'kfp==2.0.0' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef load_data(\n        data_path: str,\n        train_file: OutputPath(\"CSV\"),\n        test_file: OutputPath(\"CSV\"),\n        trajectory_file: OutputPath(\"CSV\")\n):\n    \"\"\"Loads the flight data and trajectory data.\"\"\"\n    import pandas as pd\n\n    # Load main flight data\n    train_df = pd.read_csv(\n        f\"{data_path}/challenge_set.csv\",\n        parse_dates=[\"date\", \"actual_offblock_time\", \"arrival_time\"]\n    )\n\n    test_df = pd.read_csv(\n        f\"{data_path}/submission_set.csv\",\n        parse_dates=[\"date\", \"actual_offblock_time\", \"arrival_time\"]\n    ).drop([\"tow\"], axis=1)\n\n    # Format datetime columns\n    datetime_columns = [\"date\", \"actual_offblock_time\", \"arrival_time\"]\n    for col in datetime_columns:\n        train_df[col] = train_df[col].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n        test_df[col] = test_df[col].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n\n    trajectory_df = pd.read_parquet(f\"{data_path}/2022-01-01.parquet\")\n\n    train_df.to_csv(train_file, index=False)\n    test_df.to_csv(test_file, index=False)\n    trajectory_df.to_csv(trajectory_file, index=False)\n\n"
          ],
          "image": "python:3.7"
        }
      },
      "exec-normalize-dataframe": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "normalize_dataframe"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'scikit-learn' 'kfp==2.0.0' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef normalize_dataframe(\n    input_file: InputPath(\"CSV\"),\n    output_file: OutputPath(\"CSV\"),\n    exclude_columns: list,\n    split_by_flown_distance: bool = False,\n):\n    \"\"\"Normalizes the dataframe and excludes specified columns from normalization.\"\"\"\n    import pandas as pd\n    from sklearn.preprocessing import StandardScaler\n    import numpy as np\n\n    df = pd.read_csv(input_file)\n\n    if split_by_flown_distance:\n        exclude_columns.append(\"flown_distance\")\n\n    df_normalized = df.copy()\n    columns_to_normalize = df.select_dtypes(include=[np.number]).columns.difference(\n        exclude_columns\n    )\n\n    scaler = StandardScaler()\n    df_normalized[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n\n    df_normalized.to_csv(output_file, index=False)\n\n"
          ],
          "image": "python:3.7"
        }
      }
    }
  },
  "pipelineInfo": {
    "description": "Pipeline for predicting Take-Off Weight (TOW)",
    "name": "flight-tow-prediction-pipeline"
  },
  "root": {
    "dag": {
      "tasks": {
        "add-external-data": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-add-external-data"
          },
          "dependentTasks": [
            "calculate-flight-duration",
            "load-data"
          ],
          "inputs": {
            "artifacts": {
              "test_file": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "test_file",
                  "producerTask": "load-data"
                }
              },
              "train_file": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "output_df",
                  "producerTask": "calculate-flight-duration"
                }
              }
            },
            "parameters": {
              "external_info_file": {
                "componentInputParameter": "external_data_path"
              }
            }
          },
          "taskInfo": {
            "name": "add-external-data"
          }
        },
        "calculate-and-aggregate-features": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-calculate-and-aggregate-features"
          },
          "dependentTasks": [
            "clean-dataframe-with-isolation-forest",
            "clean-trajectory-with-isolation-forest"
          ],
          "inputs": {
            "artifacts": {
              "train_df_path": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "output_df",
                  "producerTask": "clean-dataframe-with-isolation-forest"
                }
              },
              "trajectory_df_path": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "output_df",
                  "producerTask": "clean-trajectory-with-isolation-forest"
                }
              }
            },
            "parameters": {
              "flight_phases_refinement": {
                "runtimeValue": {
                  "constant": true
                }
              },
              "use_trajectory": {
                "runtimeValue": {
                  "constant": true
                }
              }
            }
          },
          "taskInfo": {
            "name": "calculate-and-aggregate-features"
          }
        },
        "calculate-flight-duration": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-calculate-flight-duration"
          },
          "dependentTasks": [
            "load-data"
          ],
          "inputs": {
            "artifacts": {
              "input_df": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "train_file",
                  "producerTask": "load-data"
                }
              }
            }
          },
          "taskInfo": {
            "name": "calculate-flight-duration"
          }
        },
        "clean-dataframe-with-isolation-forest": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-clean-dataframe-with-isolation-forest"
          },
          "dependentTasks": [
            "add-external-data"
          ],
          "inputs": {
            "artifacts": {
              "input_df": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "train_enriched_file",
                  "producerTask": "add-external-data"
                }
              }
            },
            "parameters": {
              "contamination": {
                "runtimeValue": {
                  "constant": 0.01
                }
              }
            }
          },
          "taskInfo": {
            "name": "clean-dataframe-with-isolation-forest"
          }
        },
        "clean-trajectory-with-isolation-forest": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-clean-trajectory-with-isolation-forest"
          },
          "dependentTasks": [
            "load-data"
          ],
          "inputs": {
            "artifacts": {
              "input_df": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "trajectory_file",
                  "producerTask": "load-data"
                }
              }
            },
            "parameters": {
              "contamination": {
                "runtimeValue": {
                  "constant": 0.01
                }
              }
            }
          },
          "taskInfo": {
            "name": "clean-trajectory-with-isolation-forest"
          }
        },
        "encode-categorical-features": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-encode-categorical-features"
          },
          "dependentTasks": [
            "normalize-dataframe"
          ],
          "inputs": {
            "artifacts": {
              "input_file": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "output_file",
                  "producerTask": "normalize-dataframe"
                }
              }
            },
            "parameters": {
              "preserve_columns": {
                "runtimeValue": {
                  "constant": [
                    "aircraft_type"
                  ]
                }
              }
            }
          },
          "taskInfo": {
            "name": "encode-categorical-features"
          }
        },
        "load-data": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-load-data"
          },
          "inputs": {
            "parameters": {
              "data_path": {
                "componentInputParameter": "data_path"
              }
            }
          },
          "taskInfo": {
            "name": "load-data"
          }
        },
        "normalize-dataframe": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-normalize-dataframe"
          },
          "dependentTasks": [
            "calculate-and-aggregate-features"
          ],
          "inputs": {
            "artifacts": {
              "input_file": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "aggregated_features_path",
                  "producerTask": "calculate-and-aggregate-features"
                }
              }
            },
            "parameters": {
              "exclude_columns": {
                "runtimeValue": {
                  "constant": [
                    "flight_id",
                    "tow"
                  ]
                }
              },
              "split_by_flown_distance": {
                "runtimeValue": {
                  "constant": true
                }
              }
            }
          },
          "taskInfo": {
            "name": "normalize-dataframe"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "data_path": {
          "parameterType": "STRING"
        },
        "external_data_path": {
          "parameterType": "STRING"
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.0.0"
}